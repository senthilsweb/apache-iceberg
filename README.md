# Apache Iceberg Data Lakehouse

Zero-cost Apache Iceberg lakehouse lab: Nessie catalog on Fly.io, Cloudflare R2 storage, Neon PostgreSQL backend, and PyIceberg data loader.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CSV Source    â”‚â”€â”€â”€â”€â–¶â”‚   PyIceberg      â”‚â”€â”€â”€â”€â–¶â”‚  Iceberg Table  â”‚
â”‚ (URL/File/Glob) â”‚     â”‚   + PyArrow      â”‚     â”‚    (Parquet)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚                        â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Nessie Catalog  â”‚     â”‚  Cloudflare R2  â”‚
                        â”‚   (Fly.io)       â”‚â”€â”€â”€â”€â–¶â”‚    (S3 API)     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ Neon PostgreSQL  â”‚
                        â”‚   (Metadata)     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Features

- **Pluggable Catalogs**: Nessie REST catalog or SQLite for local dev
- **Flexible Data Sources**: Load from remote URLs, local files, or directories with glob patterns
- **Auto Schema Inference**: PyArrow auto-detects CSV column types â†’ Iceberg schema
- **Table Naming**: Auto-derive from filename or specify explicitly
- **Multi-file Loading**: Process multiple CSV files with glob patterns
- **Zero Cost**: Uses free tiers of Fly.io, Cloudflare R2, and Neon

## ğŸš€ Quick Start

### 1. Clone and Setup

```bash
git clone https://github.com/senthilsweb/apache-iceberg.git
cd apache-iceberg
python3 -m venv env
source env/bin/activate
pip install -r requirements.txt
```

### 2. Configure Environment

```bash
cp sample.env .env
# Edit .env with your credentials
```

### 3. Load Data

```bash
# Option A: Using Nessie REST Catalog (Production)
ICE_SOURCE_PATH="https://raw.githubusercontent.com/senthilsweb/datasets/main/ticket/users.csv" \
ICE_NAMESPACE="ticketdb" \
ICE_TABLE_NAME="" \
ICE_CATALOG_TYPE="rest" \
ICE_NESSIE_URI="https://nessie-iceberg.fly.dev/iceberg/" \
ICE_WAREHOUSE_PATH="s3://iceberg-demo/warehouse" \
R2_ENDPOINT="https://your-account.r2.cloudflarestorage.com" \
R2_ACCESS_KEY="your-access-key" \
R2_SECRET_KEY="your-secret-key" \
python bot_iceberg_loader.py

# Option B: Using SQLite Catalog (Local Development)
ICE_SOURCE_PATH="./data/sales.csv" \
ICE_NAMESPACE="default" \
ICE_TABLE_NAME="sales" \
ICE_CATALOG_TYPE="sql" \
ICE_CATALOG_DB_PATH="./iceberg_catalog.db" \
ICE_WAREHOUSE_PATH="s3://your-bucket/warehouse" \
R2_ENDPOINT="https://your-account.r2.cloudflarestorage.com" \
R2_ACCESS_KEY="your-access-key" \
R2_SECRET_KEY="your-secret-key" \
python bot_iceberg_loader.py

# Directory with glob pattern (Nessie)
ICE_SOURCE_PATH="./data/" \
ICE_GLOB_PATTERN="*.csv" \
ICE_NAMESPACE="imports" \
ICE_CATALOG_TYPE="rest" \
ICE_NESSIE_URI="https://nessie-iceberg.fly.dev/iceberg/" \
ICE_WAREHOUSE_PATH="s3://iceberg-demo/warehouse" \
R2_ENDPOINT="https://your-account.r2.cloudflarestorage.com" \
R2_ACCESS_KEY="your-access-key" \
R2_SECRET_KEY="your-secret-key" \
python bot_iceberg_loader.py
```

## âš™ï¸ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `ICE_SOURCE_PATH` | URL, file path, or directory | Required |
| `ICE_GLOB_PATTERN` | Glob pattern for directories | `*.csv` |
| `ICE_TABLE_NAME` | Table name (derived from filename if empty) | - |
| `ICE_NAMESPACE` | Iceberg namespace | `default` |
| `ICE_CATALOG_TYPE` | `rest` (Nessie) or `sql` (SQLite) | `rest` |
| `ICE_PLURALIZE_TABLE` | Pluralize table names | `false` |
| `ICE_GLOB_MERGE_TABLE` | Merge glob files into single table | `false` |
| `ICE_NESSIE_URI` | Nessie catalog URI | - |
| `ICE_WAREHOUSE_PATH` | S3 warehouse path | - |
| `R2_ENDPOINT` | Cloudflare R2 endpoint | - |
| `R2_ACCESS_KEY` | R2 access key | - |
| `R2_SECRET_KEY` | R2 secret key | - |
| `R2_REGION` | R2 region | `auto` |

### Sample .env

```env
# Source
ICE_SOURCE_PATH=https://example.com/data.csv
ICE_NAMESPACE=default

# Catalog
ICE_CATALOG_TYPE=rest
ICE_NESSIE_URI=https://nessie-iceberg.fly.dev/iceberg/
ICE_WAREHOUSE_PATH=s3://iceberg-demo/warehouse

# Storage (Cloudflare R2)
R2_ENDPOINT=https://your-account.r2.cloudflarestorage.com
R2_ACCESS_KEY=your-access-key
R2_SECRET_KEY=your-secret-key
R2_REGION=auto
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ bot_iceberg_loader.py  # Main CSV to Iceberg loader
â”œâ”€â”€ utils.py               # Utility functions (URL detection, glob, temp files)
â”œâ”€â”€ clean_r2_warehouse.py  # Utility to clean R2 warehouse
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ sample.env             # Sample environment configuration
â”œâ”€â”€ docker-compose.yml     # Local Nessie development setup
â”œâ”€â”€ Dockerfile             # Nessie server for Fly.io
â”œâ”€â”€ fly.toml               # Fly.io deployment config
â””â”€â”€ logs/                  # Execution logs
```

## ğŸ§ª Tested Configuration

Successfully tested with:
- **Nessie Catalog**: `https://nessie-iceberg.fly.dev/iceberg/`
- **Storage**: Cloudflare R2 (`s3://iceberg-demo/warehouse`)
- **Data Source**: Remote CSV from GitHub
- **Result**: 49,990 rows loaded to `ticketdb.users` table

##  License

MIT License
